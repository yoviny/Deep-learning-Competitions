{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:32:23.297998Z",
     "iopub.status.busy": "2020-10-01T09:32:23.297227Z",
     "iopub.status.idle": "2020-10-01T09:32:50.741428Z",
     "shell.execute_reply": "2020-10-01T09:32:50.740858Z"
    },
    "papermill": {
     "duration": 27.490418,
     "end_time": "2020-10-01T09:32:50.741577",
     "exception": false,
     "start_time": "2020-10-01T09:32:23.251159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install neptune-notebooks > /dev/null # no output\n",
    "!pip install neptune-client > /dev/null # no output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-01T09:32:50.823861Z",
     "iopub.status.busy": "2020-10-01T09:32:50.823203Z",
     "iopub.status.idle": "2020-10-01T09:32:50.826729Z",
     "shell.execute_reply": "2020-10-01T09:32:50.826178Z"
    },
    "papermill": {
     "duration": 0.046528,
     "end_time": "2020-10-01T09:32:50.826849",
     "exception": false,
     "start_time": "2020-10-01T09:32:50.780321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!conda install gdcm -c conda-forge -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:32:50.912605Z",
     "iopub.status.busy": "2020-10-01T09:32:50.911894Z",
     "iopub.status.idle": "2020-10-01T09:32:50.915038Z",
     "shell.execute_reply": "2020-10-01T09:32:50.914363Z"
    },
    "papermill": {
     "duration": 0.048707,
     "end_time": "2020-10-01T09:32:50.915160",
     "exception": false,
     "start_time": "2020-10-01T09:32:50.866453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    debug=False\n",
    "    image_size=360\n",
    "    lr=8e-3\n",
    "    batch_size=1\n",
    "    epochs=200\n",
    "    seed=2018\n",
    "    N = 36\n",
    "    n_fold=5\n",
    "\n",
    "resume=False\n",
    "fp16=False\n",
    "accumulation_steps=10\n",
    "accumulate=False\n",
    "num_workers=4\n",
    "quantiles = (0.2, 0.5, 0.8)\n",
    "HM_SLICES = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-01T09:32:51.033122Z",
     "iopub.status.busy": "2020-10-01T09:32:51.025846Z",
     "iopub.status.idle": "2020-10-01T09:32:56.873572Z",
     "shell.execute_reply": "2020-10-01T09:32:56.874262Z"
    },
    "papermill": {
     "duration": 5.919143,
     "end_time": "2020-10-01T09:32:56.874413",
     "exception": false,
     "start_time": "2020-10-01T09:32:50.955270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "../input/best-autoencoder-models/model_fold_1.pt\n",
      "../input/best-autoencoder-models/model_fold_0.pt\n",
      "../input/best-autoencoder-models/model_fold_2.pt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import gc\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from IPython.core.display import display, HTML\n",
    "from time import perf_counter\n",
    "\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly import figure_factory as FF\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "from skimage import data\n",
    "from skimage import measure, feature, morphology\n",
    "from skimage.util import montage\n",
    "from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing, binary_dilation, binary_opening\n",
    "from skimage.measure import label,regionprops, perimeter\n",
    "#from skimage.filters import threshold_otsu, median\n",
    "from skimage.filters import roberts, sobel\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.exposure import equalize_hist\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold, train_test_split, TimeSeriesSplit\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init, Sequential\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau, StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "INPUT_FOLDER = '../input/osic-pulmonary-fibrosis-progression/train/'\n",
    "\n",
    "dicom_arrays_dir = Path('../input/dicom-arrays-processed/kaggle/dicom_arrays/')\n",
    "os.makedirs(dicom_arrays_dir, exist_ok=True)\n",
    "\n",
    "latent_dir = Path('/kaggle/features_dir/')\n",
    "os.makedirs(latent_dir, exist_ok=True)\n",
    "\n",
    "mask_dir = Path('/kaggle/masks/')\n",
    "os.makedirs(mask_dir, exist_ok=True)\n",
    "\n",
    "volume_array_file = Path('../input/data-stats/volume_array.pt')\n",
    "kurts_array_file = Path('../input/data-stats/kurts_array.pt')\n",
    "skews_array_file = Path('../input/data-stats/skews_array.pt')\n",
    "means_array_file = Path('../input/data-stats/mean_array.pt')\n",
    "stds_array_file = Path('../input/data-stats/std_array.pt')\n",
    "medians_array_file = Path('../input/data-stats/median_array.pt')\n",
    "\n",
    "model_dir = '../input/best-autoencoder-models'\n",
    "\n",
    "MODELS = []\n",
    "for filename in os.listdir(model_dir):\n",
    "    if filename.endswith(\".pt\"): \n",
    "        print(os.path.join(model_dir, filename))\n",
    "        MODELS.append(os.path.join(model_dir, filename))\n",
    "\n",
    "#patients = os.listdir(INPUT_FOLDER)\n",
    "#patients.sort()\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.568885,
     "end_time": "2020-10-01T09:32:59.572082",
     "exception": false,
     "start_time": "2020-10-01T09:32:57.003197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import neptune\n",
    "neptune.init(api_token=os.getenv('NEPTUNE_API_TOKEN'),\n",
    "             project_qualified_name=os.getenv('NEPTUNE_PROJECT'))\n",
    "\n",
    "params={'epochs': CFG.epochs,\n",
    "        'batch_size': CFG.batch_size,\n",
    "        'lr': CFG.lr}\n",
    "\n",
    "neptune.create_experiment(name='lstm-train', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:32:59.690443Z",
     "iopub.status.busy": "2020-10-01T09:32:59.689065Z",
     "iopub.status.idle": "2020-10-01T09:32:59.697742Z",
     "shell.execute_reply": "2020-10-01T09:32:59.697048Z"
    },
    "papermill": {
     "duration": 0.068335,
     "end_time": "2020-10-01T09:32:59.697864",
     "exception": false,
     "start_time": "2020-10-01T09:32:59.629529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
    "\n",
    "    \n",
    "def init_logger(log_file='train.log'):\n",
    "    from logging import getLogger, DEBUG, FileHandler,  Formatter,  StreamHandler\n",
    "    \n",
    "    log_format = '%(asctime)s %(levelname)s %(message)s'\n",
    "    \n",
    "    stream_handler = StreamHandler()\n",
    "    stream_handler.setLevel(DEBUG)\n",
    "    stream_handler.setFormatter(Formatter(log_format))\n",
    "    \n",
    "    file_handler = FileHandler(log_file)\n",
    "    file_handler.setFormatter(Formatter(log_format))\n",
    "    \n",
    "    logger = getLogger('fibrosis')\n",
    "    logger.setLevel(DEBUG)\n",
    "    logger.addHandler(stream_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "LOG_FILE = 'train.log'\n",
    "LOGGER = init_logger(LOG_FILE)\n",
    "\n",
    "\n",
    "def seed_torch(seed=2020):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:32:59.784472Z",
     "iopub.status.busy": "2020-10-01T09:32:59.783792Z",
     "iopub.status.idle": "2020-10-01T09:32:59.794609Z",
     "shell.execute_reply": "2020-10-01T09:32:59.793997Z"
    },
    "papermill": {
     "duration": 0.056148,
     "end_time": "2020-10-01T09:32:59.794731",
     "exception": false,
     "start_time": "2020-10-01T09:32:59.738583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of folders: 176\n"
     ]
    }
   ],
   "source": [
    "patient_files = list(os.listdir(INPUT_FOLDER))\n",
    "print(\"Number of folders:\", len(patient_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:32:59.889543Z",
     "iopub.status.busy": "2020-10-01T09:32:59.888710Z",
     "iopub.status.idle": "2020-10-01T09:32:59.946138Z",
     "shell.execute_reply": "2020-10-01T09:32:59.945542Z"
    },
    "papermill": {
     "duration": 0.110206,
     "end_time": "2020-10-01T09:32:59.946266",
     "exception": false,
     "start_time": "2020-10-01T09:32:59.836060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/train.csv')\n",
    "train_csv = train_csv.drop_duplicates(subset=['Patient', 'Weeks'])\n",
    "test_csv = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/test.csv')\n",
    "sub_csv = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/sample_submission.csv')\n",
    "\n",
    "sub_csv['Weeks']   = sub_csv['Patient_Week'].apply( lambda x: int(x.split('_')[-1]) )\n",
    "sub_csv['Patient'] = sub_csv['Patient_Week'].apply( lambda x: x.split('_')[0] ) \n",
    "sub_csv =  sub_csv[['Patient','Weeks','Confidence','Patient_Week']]\n",
    "sub_csv = sub_csv.merge(test_csv.drop('Weeks', axis=1), on=\"Patient\")\n",
    "\n",
    "train_csv['WHERE'] = 'train'\n",
    "test_csv['WHERE'] = 'val'\n",
    "sub_csv['WHERE'] = 'test'\n",
    "data = train_csv.append([sub_csv, test_csv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:00.038622Z",
     "iopub.status.busy": "2020-10-01T09:33:00.037601Z",
     "iopub.status.idle": "2020-10-01T09:33:00.044573Z",
     "shell.execute_reply": "2020-10-01T09:33:00.043730Z"
    },
    "papermill": {
     "duration": 0.057868,
     "end_time": "2020-10-01T09:33:00.044725",
     "exception": false,
     "start_time": "2020-10-01T09:32:59.986857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Patient', 'Weeks', 'FVC', 'Percent', 'Age', 'Sex', 'SmokingStatus', 'WHERE', 'Confidence', 'Patient_Week']\n",
      "(1542, 8) (5, 8) (730, 10) (2277, 10)\n",
      "176 5 5 176\n"
     ]
    }
   ],
   "source": [
    "columns = data.keys()\n",
    "columns = list(columns)\n",
    "print(columns)\n",
    "\n",
    "print(train_csv.shape, test_csv.shape, sub_csv.shape, data.shape)\n",
    "print(train_csv.Patient.nunique(), test_csv.Patient.nunique(), sub_csv.Patient.nunique(), \n",
    "      data.Patient.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:00.138305Z",
     "iopub.status.busy": "2020-10-01T09:33:00.137608Z",
     "iopub.status.idle": "2020-10-01T09:33:00.189119Z",
     "shell.execute_reply": "2020-10-01T09:33:00.188510Z"
    },
    "papermill": {
     "duration": 0.102773,
     "end_time": "2020-10-01T09:33:00.189252",
     "exception": false,
     "start_time": "2020-10-01T09:33:00.086479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['min_week'] = data['Weeks']\n",
    "data.loc[data.WHERE=='test','min_week'] = np.nan\n",
    "data['min_week'] = data.groupby('Patient')['min_week'].transform('min')\n",
    "\n",
    "base = data.loc[data.Weeks == data.min_week]\n",
    "base = base[['Patient','FVC']].copy()\n",
    "base.columns = ['Patient','min_FVC']\n",
    "base['nb'] = 1\n",
    "base['nb'] = base.groupby('Patient')['nb'].transform('cumsum')\n",
    "base = base[base.nb==1]\n",
    "base.drop('nb', axis=1, inplace=True)\n",
    "\n",
    "data = data.merge(base, on='Patient', how='left')\n",
    "data['base_week'] = data['Weeks'] - data['min_week']\n",
    "del base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:00.284268Z",
     "iopub.status.busy": "2020-10-01T09:33:00.280938Z",
     "iopub.status.idle": "2020-10-01T09:33:00.287771Z",
     "shell.execute_reply": "2020-10-01T09:33:00.287087Z"
    },
    "papermill": {
     "duration": 0.057041,
     "end_time": "2020-10-01T09:33:00.287894",
     "exception": false,
     "start_time": "2020-10-01T09:33:00.230853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "COLS = ['Sex','SmokingStatus']\n",
    "FE = []\n",
    "for col in COLS:\n",
    "    for mod in data[col].unique():\n",
    "        FE.append(mod)\n",
    "        data[mod] = (data[col] == mod).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:00.490103Z",
     "iopub.status.busy": "2020-10-01T09:33:00.487415Z",
     "iopub.status.idle": "2020-10-01T09:33:00.508385Z",
     "shell.execute_reply": "2020-10-01T09:33:00.507596Z"
    },
    "papermill": {
     "duration": 0.088206,
     "end_time": "2020-10-01T09:33:00.508511",
     "exception": false,
     "start_time": "2020-10-01T09:33:00.420305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "      <th>WHERE</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Patient_Week</th>\n",
       "      <th>...</th>\n",
       "      <th>base_week</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Ex-smoker</th>\n",
       "      <th>Never smoked</th>\n",
       "      <th>Currently smokes</th>\n",
       "      <th>age</th>\n",
       "      <th>BASE</th>\n",
       "      <th>week</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.236393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>5</td>\n",
       "      <td>2214</td>\n",
       "      <td>55.712129</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.234568</td>\n",
       "      <td>0.215941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>7</td>\n",
       "      <td>2061</td>\n",
       "      <td>51.862104</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.184960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>9</td>\n",
       "      <td>2144</td>\n",
       "      <td>53.950679</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.201767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>11</td>\n",
       "      <td>2069</td>\n",
       "      <td>52.063412</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.186580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus  \\\n",
       "0  ID00007637202177411956430     -4  2315  58.253649   79  Male     Ex-smoker   \n",
       "1  ID00007637202177411956430      5  2214  55.712129   79  Male     Ex-smoker   \n",
       "2  ID00007637202177411956430      7  2061  51.862104   79  Male     Ex-smoker   \n",
       "3  ID00007637202177411956430      9  2144  53.950679   79  Male     Ex-smoker   \n",
       "4  ID00007637202177411956430     11  2069  52.063412   79  Male     Ex-smoker   \n",
       "\n",
       "   WHERE  Confidence Patient_Week  ...  base_week  Male  Female  Ex-smoker  \\\n",
       "0  train         NaN          NaN  ...        0.0     1       0          1   \n",
       "1  train         NaN          NaN  ...        9.0     1       0          1   \n",
       "2  train         NaN          NaN  ...       11.0     1       0          1   \n",
       "3  train         NaN          NaN  ...       13.0     1       0          1   \n",
       "4  train         NaN          NaN  ...       15.0     1       0          1   \n",
       "\n",
       "   Never smoked  Currently smokes       age      BASE      week   percent  \n",
       "0             0                 0  0.769231  0.241456  0.179012  0.236393  \n",
       "1             0                 0  0.769231  0.241456  0.234568  0.215941  \n",
       "2             0                 0  0.769231  0.241456  0.246914  0.184960  \n",
       "3             0                 0  0.769231  0.241456  0.259259  0.201767  \n",
       "4             0                 0  0.769231  0.241456  0.271605  0.186580  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['age'] = (data['Age'] - data['Age'].min() ) / ( data['Age'].max() - data['Age'].min() )\n",
    "data['BASE'] = (data['min_FVC'] - data['min_FVC'].min() ) / ( data['min_FVC'].max() - data['min_FVC'].min() )\n",
    "data['week'] = (data['base_week'] - data['base_week'].min() ) / ( data['base_week'].max() - data['base_week'].min() )\n",
    "data['percent'] = (data['Percent'] - data['Percent'].min() ) / ( data['Percent'].max() - data['Percent'].min() )\n",
    "FE += ['age','percent','week','BASE']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:00.601512Z",
     "iopub.status.busy": "2020-10-01T09:33:00.600781Z",
     "iopub.status.idle": "2020-10-01T09:33:00.632301Z",
     "shell.execute_reply": "2020-10-01T09:33:00.633007Z"
    },
    "papermill": {
     "duration": 0.082267,
     "end_time": "2020-10-01T09:33:00.633200",
     "exception": false,
     "start_time": "2020-10-01T09:33:00.550933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index', 'Patient', 'Weeks', 'FVC', 'Percent', 'Age', 'Sex', 'SmokingStatus', 'WHERE', 'Confidence', 'Patient_Week', 'min_week', 'min_FVC', 'base_week', 'Male', 'Female', 'Ex-smoker', 'Never smoked', 'Currently smokes', 'age', 'BASE', 'week', 'percent']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "      <th>WHERE</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>base_week</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Ex-smoker</th>\n",
       "      <th>Never smoked</th>\n",
       "      <th>Currently smokes</th>\n",
       "      <th>age</th>\n",
       "      <th>BASE</th>\n",
       "      <th>week</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.236393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>5</td>\n",
       "      <td>2214</td>\n",
       "      <td>55.712129</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.234568</td>\n",
       "      <td>0.215941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>7</td>\n",
       "      <td>2061</td>\n",
       "      <td>51.862104</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.184960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>9</td>\n",
       "      <td>2144</td>\n",
       "      <td>53.950679</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.201767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>11</td>\n",
       "      <td>2069</td>\n",
       "      <td>52.063412</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.186580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                    Patient  Weeks   FVC    Percent  Age   Sex  \\\n",
       "0      0  ID00007637202177411956430     -4  2315  58.253649   79  Male   \n",
       "1      1  ID00007637202177411956430      5  2214  55.712129   79  Male   \n",
       "2      2  ID00007637202177411956430      7  2061  51.862104   79  Male   \n",
       "3      3  ID00007637202177411956430      9  2144  53.950679   79  Male   \n",
       "4      4  ID00007637202177411956430     11  2069  52.063412   79  Male   \n",
       "\n",
       "  SmokingStatus  WHERE  Confidence  ... base_week  Male  Female  Ex-smoker  \\\n",
       "0     Ex-smoker  train         NaN  ...       0.0     1       0          1   \n",
       "1     Ex-smoker  train         NaN  ...       9.0     1       0          1   \n",
       "2     Ex-smoker  train         NaN  ...      11.0     1       0          1   \n",
       "3     Ex-smoker  train         NaN  ...      13.0     1       0          1   \n",
       "4     Ex-smoker  train         NaN  ...      15.0     1       0          1   \n",
       "\n",
       "   Never smoked  Currently smokes       age      BASE      week   percent  \n",
       "0             0                 0  0.769231  0.241456  0.179012  0.236393  \n",
       "1             0                 0  0.769231  0.241456  0.234568  0.215941  \n",
       "2             0                 0  0.769231  0.241456  0.246914  0.184960  \n",
       "3             0                 0  0.769231  0.241456  0.259259  0.201767  \n",
       "4             0                 0  0.769231  0.241456  0.271605  0.186580  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_df = data.loc[data.WHERE=='train'].reset_index()\n",
    "#chunk = data.loc[data.WHERE=='val']\n",
    "#sub = data.loc[data.WHERE=='test']\n",
    "del data\n",
    "\n",
    "columns = patient_df.keys()\n",
    "columns = list(columns)\n",
    "print(columns)\n",
    "patient_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:00.727529Z",
     "iopub.status.busy": "2020-10-01T09:33:00.726637Z",
     "iopub.status.idle": "2020-10-01T09:33:00.730063Z",
     "shell.execute_reply": "2020-10-01T09:33:00.729413Z"
    },
    "papermill": {
     "duration": 0.054281,
     "end_time": "2020-10-01T09:33:00.730176",
     "exception": false,
     "start_time": "2020-10-01T09:33:00.675895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_scan(path):\n",
    "    slices = [pydicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: float(x.InstanceNumber))\n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    except NameError:\n",
    "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "    except:\n",
    "        slice_thickness = slices[0].SliceThickness\n",
    "        \n",
    "    if slice_thickness==0:\n",
    "            slice_thickness=slices[0].SliceThickness\n",
    "    for s in slices:\n",
    "        s.SliceThickness = slice_thickness\n",
    "    \n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:00.826060Z",
     "iopub.status.busy": "2020-10-01T09:33:00.825057Z",
     "iopub.status.idle": "2020-10-01T09:33:00.828520Z",
     "shell.execute_reply": "2020-10-01T09:33:00.827823Z"
    },
    "papermill": {
     "duration": 0.0562,
     "end_time": "2020-10-01T09:33:00.828661",
     "exception": false,
     "start_time": "2020-10-01T09:33:00.772461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pixels_hu(slices):\n",
    "    image = np.stack([s.pixel_array for s in slices])\n",
    "    # Convert to int16\n",
    "    image = image.astype(np.int16)\n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    # Convert to Hounsfield units (HU)\n",
    "    for slice_number in range(len(slices)):\n",
    "        intercept = slices[slice_number].RescaleIntercept\n",
    "        slope = slices[slice_number].RescaleSlope\n",
    "        if slope != 1:\n",
    "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
    "            image[slice_number] = image[slice_number].astype(np.int16)\n",
    "        image[slice_number] += np.int16(intercept)\n",
    "    return np.array(image, dtype=np.int16)\n",
    "\n",
    "def window_image(image, window_center, window_width):\n",
    "    img_min = window_center - window_width // 2\n",
    "    img_max = window_center + window_width // 2\n",
    "    window_image = image.copy()\n",
    "    window_image[window_image < img_min] = img_min\n",
    "    window_image[window_image > img_max] = img_max\n",
    "    return window_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:00.922114Z",
     "iopub.status.busy": "2020-10-01T09:33:00.921271Z",
     "iopub.status.idle": "2020-10-01T09:33:00.924742Z",
     "shell.execute_reply": "2020-10-01T09:33:00.924201Z"
    },
    "papermill": {
     "duration": 0.053542,
     "end_time": "2020-10-01T09:33:00.924856",
     "exception": false,
     "start_time": "2020-10-01T09:33:00.871314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resample(image, scan, new_spacing=[1,1,1]):\n",
    "    # Determine current pixel spacing\n",
    "    spacing = np.array([scan[0].SliceThickness] + list(scan[0].PixelSpacing), dtype=np.float32)\n",
    "\n",
    "    resize_factor = spacing / new_spacing\n",
    "    new_real_shape = image.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    new_spacing = spacing / real_resize_factor\n",
    "    \n",
    "    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n",
    "    \n",
    "    return image, new_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:01.020330Z",
     "iopub.status.busy": "2020-10-01T09:33:01.019531Z",
     "iopub.status.idle": "2020-10-01T09:33:01.024701Z",
     "shell.execute_reply": "2020-10-01T09:33:01.025198Z"
    },
    "papermill": {
     "duration": 0.058286,
     "end_time": "2020-10-01T09:33:01.025375",
     "exception": false,
     "start_time": "2020-10-01T09:33:00.967089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_segmented_lungs(im, threshold):\n",
    "    '''\n",
    "    Step 1: Convert into a binary image. \n",
    "    '''\n",
    "    binary = np.array(im < threshold, dtype=np.int8)\n",
    "    '''\n",
    "    Step 2: Remove the blobs connected to the border of the image.\n",
    "    '''\n",
    "    cleared = clear_border(binary)\n",
    "    '''\n",
    "    Step 3: Label the image.\n",
    "    '''\n",
    "    label_image = label(cleared)\n",
    "    '''\n",
    "    Step 4: Keep the labels with 2 largest areas.\n",
    "    '''\n",
    "    areas = [r.area for r in regionprops(label_image)]\n",
    "    areas.sort()\n",
    "    if len(areas) > 2:\n",
    "        for region in regionprops(label_image):\n",
    "            if region.area < areas[-2]:\n",
    "                for coordinates in region.coords:                \n",
    "                       label_image[coordinates[0], coordinates[1]] = 0\n",
    "    binary = label_image > 0\n",
    "    '''\n",
    "    Step 5: Erosion operation with a disk of radius 2. This operation is \n",
    "    seperate the lung nodules attached to the blood vessels.\n",
    "    '''\n",
    "    selem = disk(2)\n",
    "    binary = binary_erosion(binary, selem)\n",
    "    '''\n",
    "    Step 6: Closure operation with a disk of radius 10. This operation is \n",
    "    to keep nodules attached to the lung wall.\n",
    "    '''\n",
    "    selem = disk(10)\n",
    "    binary = binary_closing(binary, selem)\n",
    "    '''\n",
    "    Step 7: Fill in the small holes inside the binary mask of lungs.\n",
    "    '''\n",
    "    edges = roberts(binary)\n",
    "    binary = ndi.binary_fill_holes(edges)\n",
    "    '''\n",
    "    Step 8: Superimpose the binary mask on the input image.\n",
    "    '''\n",
    "#     get_high_vals = binary == 0\n",
    "#     im[get_high_vals] = 0\n",
    "    im = binary* im\n",
    "        \n",
    "    return im, binary.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:01.123955Z",
     "iopub.status.busy": "2020-10-01T09:33:01.123237Z",
     "iopub.status.idle": "2020-10-01T09:33:01.126578Z",
     "shell.execute_reply": "2020-10-01T09:33:01.125938Z"
    },
    "papermill": {
     "duration": 0.058679,
     "end_time": "2020-10-01T09:33:01.126697",
     "exception": false,
     "start_time": "2020-10-01T09:33:01.068018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#MIN_BOUND = -1000.0\n",
    "#MAX_BOUND = 320.0\n",
    "    \n",
    "def normalize(image, MIN_BOUND, MAX_BOUND):\n",
    "    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
    "    image[image>1] = 1.\n",
    "    image[image<0] = 0.\n",
    "    return image\n",
    "\n",
    "def lung_volume(masks, spacing):\n",
    "    slice_thickness = spacing[0]\n",
    "    pixel_spacing = (spacing[1], spacing[2])\n",
    "    \n",
    "    return np.round(np.sum(masks) * slice_thickness * pixel_spacing[0]*pixel_spacing[1], 3)\n",
    "\n",
    "def lung_process(image, spacing, threshold):\n",
    "    segmented = []\n",
    "    masks = []\n",
    "    for im in image:\n",
    "        segment,mask = get_segmented_lungs(im,threshold)\n",
    "        masks.append(mask.astype(int))\n",
    "        segmented.append(segment)\n",
    "    #vol = lung_volume(np.asarray(masks), spacing)\n",
    "    return np.asarray(segmented), np.asarray(masks)\n",
    "\n",
    "def compute_stats(img):\n",
    "    kurt = kurtosis(img.ravel()[img.ravel() <0.6])\n",
    "    ske = skew(img.ravel()[img.ravel() <0.6])\n",
    "\n",
    "    std_i = img.ravel()[img.ravel() <0.6].std()\n",
    "    mean_i = img.ravel()[img.ravel() <0.6].mean()\n",
    "    median_i = np.median(img.ravel()[img.ravel() <0.6])\n",
    "    return kurt, ske, std_i, mean_i, median_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:01.407956Z",
     "iopub.status.busy": "2020-10-01T09:33:01.407296Z",
     "iopub.status.idle": "2020-10-01T09:33:01.410331Z",
     "shell.execute_reply": "2020-10-01T09:33:01.410809Z"
    },
    "papermill": {
     "duration": 0.056155,
     "end_time": "2020-10-01T09:33:01.410966",
     "exception": false,
     "start_time": "2020-10-01T09:33:01.354811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_file(patient_id):\n",
    "    patient = load_scan(INPUT_FOLDER + patient_id)\n",
    "    patient_pixels = get_pixels_hu(patient)\n",
    "    \n",
    "    if patient_pixels.mean()<-1500 and patient_pixels.mean()>=-1800:\n",
    "        lung_image = window_image(patient_pixels, -1500, 3000)\n",
    "        pix_resampled, spacing = resample(lung_image, patient, [1,1,1])\n",
    "        segmented, mask = lung_process(pix_resampled, spacing, -1400)\n",
    "        normalized = normalize(segmented, -3000, 1500)\n",
    "        \n",
    "    elif patient_pixels.mean()<-1800:\n",
    "        lung_image = window_image(patient_pixels, -3000, 4500)\n",
    "        pix_resampled, spacing = resample(lung_image, patient, [1,1,1])\n",
    "        segmented, mask = lung_process(pix_resampled, spacing, -2200)\n",
    "        normalized = normalize(segmented, -4000, 300)\n",
    "        \n",
    "    else:\n",
    "        lung_image = window_image(patient_pixels, -300, 1200)\n",
    "        pix_resampled, spacing = resample(lung_image, patient, [1,1,1])\n",
    "        segmented, mask = lung_process(pix_resampled, spacing, -200)\n",
    "        normalized = normalize(segmented, -1500, 900)\n",
    "        \n",
    "    return normalized.astype(np.float16), mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:01.509932Z",
     "iopub.status.busy": "2020-10-01T09:33:01.509213Z",
     "iopub.status.idle": "2020-10-01T09:33:01.512688Z",
     "shell.execute_reply": "2020-10-01T09:33:01.512043Z"
    },
    "papermill": {
     "duration": 0.058643,
     "end_time": "2020-10-01T09:33:01.512803",
     "exception": false,
     "start_time": "2020-10-01T09:33:01.454160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    # Credit: Ned Batchelder\n",
    "    # Link: http://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def mean(l):\n",
    "    return sum(l) / len(l)\n",
    "\n",
    "def reduce_slices(slices):\n",
    "    new_slices = []\n",
    "    chunk_sizes = math.ceil(len(slices) / HM_SLICES)\n",
    "    for slice_chunk in chunks(slices, chunk_sizes):\n",
    "        slice_chunk = list(map(mean, zip(*slice_chunk)))\n",
    "        new_slices.append(slice_chunk)\n",
    "\n",
    "    if len(new_slices) == HM_SLICES-1:\n",
    "        new_slices.append(new_slices[-1])\n",
    "\n",
    "    if len(new_slices) == HM_SLICES-2:\n",
    "        new_slices.append(new_slices[-1])\n",
    "        new_slices.append(new_slices[-1])\n",
    "\n",
    "    if len(new_slices) == HM_SLICES+2:\n",
    "        new_val = list(map(mean, zip(*[new_slices[HM_SLICES-1],new_slices[HM_SLICES],])))\n",
    "        del new_slices[HM_SLICES]\n",
    "        new_slices[HM_SLICES-1] = new_val\n",
    "\n",
    "    if len(new_slices) == HM_SLICES+1:\n",
    "        new_val = list(map(mean, zip(*[new_slices[HM_SLICES-1],new_slices[HM_SLICES],])))\n",
    "        del new_slices[HM_SLICES]\n",
    "        new_slices[HM_SLICES-1] = new_val\n",
    "    return new_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:01.608881Z",
     "iopub.status.busy": "2020-10-01T09:33:01.608086Z",
     "iopub.status.idle": "2020-10-01T09:33:01.611292Z",
     "shell.execute_reply": "2020-10-01T09:33:01.610739Z"
    },
    "papermill": {
     "duration": 0.054944,
     "end_time": "2020-10-01T09:33:01.611407",
     "exception": false,
     "start_time": "2020-10-01T09:33:01.556463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_img = dicom_arrays_dir\n",
    "save_mask = mask_dir\n",
    "def save_arrays(patient_ids):\n",
    "    segmented, mask = preprocess_file(patient_ids)\n",
    "    array_path = f'{save_img}/{patient_ids}.npy'\n",
    "    mask_path = f'{save_mask}/{patient_ids}_mask.npy'\n",
    "    \n",
    "    np.save(str(array_path), segmented)\n",
    "    np.save(str(mask_path), mask)\n",
    "    gc.collect()\n",
    "\n",
    "def cache_dataset():\n",
    "    patient_ids = patient_df.drop_duplicates(subset=['Patient']).Patient\n",
    "\n",
    "    with Pool(processes=4) as pool:\n",
    "        show_run_results = list(\n",
    "            tqdm(pool.imap(save_arrays, patient_ids), total = len(patient_ids))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:01.712123Z",
     "iopub.status.busy": "2020-10-01T09:33:01.711263Z",
     "iopub.status.idle": "2020-10-01T09:33:01.730574Z",
     "shell.execute_reply": "2020-10-01T09:33:01.731145Z"
    },
    "papermill": {
     "duration": 0.077043,
     "end_time": "2020-10-01T09:33:01.731310",
     "exception": false,
     "start_time": "2020-10-01T09:33:01.654267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pre-calculated arrays\n"
     ]
    }
   ],
   "source": [
    "if volume_array_file.exists() and kurts_array_file.exists():\n",
    "    print('loading pre-calculated arrays')\n",
    "    volumes = torch.load(volume_array_file)\n",
    "    kurts = torch.load(kurts_array_file)\n",
    "    skews = torch.load(skews_array_file)\n",
    "    means = torch.load(means_array_file)\n",
    "    stds = torch.load(stds_array_file)\n",
    "    medians = torch.load(medians_array_file)\n",
    "    \n",
    "    temp_df= patient_df.copy().drop_duplicates(subset=['Patient'])\n",
    "else:\n",
    "    print('Process dicom images and caching dataset...')\n",
    "    volumes = []\n",
    "    kurts = []\n",
    "    skews = []\n",
    "    means = []\n",
    "    stds = []\n",
    "    medians = []\n",
    "    \n",
    "    cache_dataset()\n",
    "    \n",
    "    temp_df= patient_df.copy().drop_duplicates(subset=['Patient'])\n",
    "    print('Calculating image statistics...')\n",
    "    \n",
    "    for i, patient_id in tqdm(enumerate(temp_df.Patient), total=len(temp_df.Patient)):\n",
    "        segmented = []\n",
    "        cached_img_path = f'{dicom_arrays_dir}/{patient_id}.npy'\n",
    "        cached_mask_file = mask_dir/f'{patient_id}_mask.npy'\n",
    "\n",
    "        img_array = np.load(cached_img_path)\n",
    "        mask = np.load(cached_mask_file)\n",
    "        \n",
    "        vol = lung_volume(np.asarray(mask), (1,1,1))\n",
    "        kurt, ske, std_i, mean_i, median_i = compute_stats(img_array)\n",
    "        \n",
    "        volumes.append(vol)\n",
    "        means.append(mean_i)\n",
    "        stds.append(std_i)\n",
    "        medians.append(median_i)\n",
    "        kurts.append(kurt)\n",
    "        skews.append(ske)\n",
    "        \n",
    "        gc.collect()\n",
    "\n",
    "    torch.save(volumes, 'volume_array.pt')\n",
    "    torch.save(kurts, 'kurts_array.pt')\n",
    "    torch.save(skews, 'skews_array.pt')\n",
    "    torch.save(means, 'mean_array.pt')\n",
    "    torch.save(stds, 'std_array.pt')\n",
    "    torch.save(medians, 'median_array.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:01.850144Z",
     "iopub.status.busy": "2020-10-01T09:33:01.849171Z",
     "iopub.status.idle": "2020-10-01T09:33:01.854344Z",
     "shell.execute_reply": "2020-10-01T09:33:01.853867Z"
    },
    "papermill": {
     "duration": 0.079559,
     "end_time": "2020-10-01T09:33:01.854460",
     "exception": false,
     "start_time": "2020-10-01T09:33:01.774901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "      <th>WHERE</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>Never smoked</th>\n",
       "      <th>Currently smokes</th>\n",
       "      <th>age</th>\n",
       "      <th>BASE</th>\n",
       "      <th>week</th>\n",
       "      <th>percent</th>\n",
       "      <th>volume</th>\n",
       "      <th>kurts</th>\n",
       "      <th>skews</th>\n",
       "      <th>mean_vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.236393</td>\n",
       "      <td>3.515550</td>\n",
       "      <td>0.742115</td>\n",
       "      <td>1.192383</td>\n",
       "      <td>0.326172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>ID00009637202177434476278</td>\n",
       "      <td>8</td>\n",
       "      <td>3660</td>\n",
       "      <td>85.282878</td>\n",
       "      <td>69</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.491270</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.453901</td>\n",
       "      <td>4.552959</td>\n",
       "      <td>2.920642</td>\n",
       "      <td>1.780273</td>\n",
       "      <td>0.300293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>ID00010637202177584971671</td>\n",
       "      <td>0</td>\n",
       "      <td>3523</td>\n",
       "      <td>94.724672</td>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.465825</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.529881</td>\n",
       "      <td>2.481575</td>\n",
       "      <td>0.693160</td>\n",
       "      <td>1.090820</td>\n",
       "      <td>0.337402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>ID00011637202177653955184</td>\n",
       "      <td>6</td>\n",
       "      <td>3326</td>\n",
       "      <td>85.987590</td>\n",
       "      <td>72</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.429235</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.459572</td>\n",
       "      <td>4.649744</td>\n",
       "      <td>1.347476</td>\n",
       "      <td>1.318359</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>ID00012637202177665765362</td>\n",
       "      <td>33</td>\n",
       "      <td>3418</td>\n",
       "      <td>93.726006</td>\n",
       "      <td>65</td>\n",
       "      <td>Male</td>\n",
       "      <td>Never smoked</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.446322</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.521844</td>\n",
       "      <td>4.414031</td>\n",
       "      <td>2.529640</td>\n",
       "      <td>1.617188</td>\n",
       "      <td>0.303711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                    Patient  Weeks   FVC    Percent  Age   Sex  \\\n",
       "0       0  ID00007637202177411956430     -4  2315  58.253649   79  Male   \n",
       "9       9  ID00009637202177434476278      8  3660  85.282878   69  Male   \n",
       "18     18  ID00010637202177584971671      0  3523  94.724672   60  Male   \n",
       "27     27  ID00011637202177653955184      6  3326  85.987590   72  Male   \n",
       "36     36  ID00012637202177665765362     33  3418  93.726006   65  Male   \n",
       "\n",
       "   SmokingStatus  WHERE  Confidence  ... Never smoked  Currently smokes  \\\n",
       "0      Ex-smoker  train         NaN  ...            0                 0   \n",
       "9      Ex-smoker  train         NaN  ...            0                 0   \n",
       "18     Ex-smoker  train         NaN  ...            0                 0   \n",
       "27     Ex-smoker  train         NaN  ...            0                 0   \n",
       "36  Never smoked  train         NaN  ...            1                 0   \n",
       "\n",
       "         age      BASE      week   percent    volume     kurts     skews  \\\n",
       "0   0.769231  0.241456  0.179012  0.236393  3.515550  0.742115  1.192383   \n",
       "9   0.512821  0.491270  0.179012  0.453901  4.552959  2.920642  1.780273   \n",
       "18  0.282051  0.465825  0.179012  0.529881  2.481575  0.693160  1.090820   \n",
       "27  0.589744  0.429235  0.179012  0.459572  4.649744  1.347476  1.318359   \n",
       "36  0.410256  0.446322  0.179012  0.521844  4.414031  2.529640  1.617188   \n",
       "\n",
       "    mean_vals  \n",
       "0    0.326172  \n",
       "9    0.300293  \n",
       "18   0.337402  \n",
       "27   0.312500  \n",
       "36   0.303711  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df[\"volume\"] = np.asarray(volumes)/1e6\n",
    "temp_df[\"kurts\"] = kurts\n",
    "temp_df[\"skews\"] = skews\n",
    "temp_df[\"mean_vals\"] = means\n",
    "#temp_df[\"std_vals\"] = stds\n",
    "#temp_df[\"median_vals\"] = medians\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:01.950838Z",
     "iopub.status.busy": "2020-10-01T09:33:01.947782Z",
     "iopub.status.idle": "2020-10-01T09:33:01.985410Z",
     "shell.execute_reply": "2020-10-01T09:33:01.985936Z"
    },
    "papermill": {
     "duration": 0.088591,
     "end_time": "2020-10-01T09:33:01.986094",
     "exception": false,
     "start_time": "2020-10-01T09:33:01.897503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1542\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "      <th>WHERE</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>Never smoked</th>\n",
       "      <th>Currently smokes</th>\n",
       "      <th>age</th>\n",
       "      <th>BASE</th>\n",
       "      <th>week</th>\n",
       "      <th>percent</th>\n",
       "      <th>volume</th>\n",
       "      <th>kurts</th>\n",
       "      <th>skews</th>\n",
       "      <th>mean_vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.236393</td>\n",
       "      <td>3.51555</td>\n",
       "      <td>0.742115</td>\n",
       "      <td>1.192383</td>\n",
       "      <td>0.326172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>5</td>\n",
       "      <td>2214</td>\n",
       "      <td>55.712129</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.234568</td>\n",
       "      <td>0.215941</td>\n",
       "      <td>3.51555</td>\n",
       "      <td>0.742115</td>\n",
       "      <td>1.192383</td>\n",
       "      <td>0.326172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>7</td>\n",
       "      <td>2061</td>\n",
       "      <td>51.862104</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.184960</td>\n",
       "      <td>3.51555</td>\n",
       "      <td>0.742115</td>\n",
       "      <td>1.192383</td>\n",
       "      <td>0.326172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>9</td>\n",
       "      <td>2144</td>\n",
       "      <td>53.950679</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.201767</td>\n",
       "      <td>3.51555</td>\n",
       "      <td>0.742115</td>\n",
       "      <td>1.192383</td>\n",
       "      <td>0.326172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>11</td>\n",
       "      <td>2069</td>\n",
       "      <td>52.063412</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.186580</td>\n",
       "      <td>3.51555</td>\n",
       "      <td>0.742115</td>\n",
       "      <td>1.192383</td>\n",
       "      <td>0.326172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                    Patient  Weeks   FVC    Percent  Age   Sex  \\\n",
       "0      0  ID00007637202177411956430     -4  2315  58.253649   79  Male   \n",
       "1      1  ID00007637202177411956430      5  2214  55.712129   79  Male   \n",
       "2      2  ID00007637202177411956430      7  2061  51.862104   79  Male   \n",
       "3      3  ID00007637202177411956430      9  2144  53.950679   79  Male   \n",
       "4      4  ID00007637202177411956430     11  2069  52.063412   79  Male   \n",
       "\n",
       "  SmokingStatus  WHERE  Confidence  ... Never smoked  Currently smokes  \\\n",
       "0     Ex-smoker  train         NaN  ...            0                 0   \n",
       "1     Ex-smoker  train         NaN  ...            0                 0   \n",
       "2     Ex-smoker  train         NaN  ...            0                 0   \n",
       "3     Ex-smoker  train         NaN  ...            0                 0   \n",
       "4     Ex-smoker  train         NaN  ...            0                 0   \n",
       "\n",
       "        age      BASE      week   percent   volume     kurts     skews  \\\n",
       "0  0.769231  0.241456  0.179012  0.236393  3.51555  0.742115  1.192383   \n",
       "1  0.769231  0.241456  0.234568  0.215941  3.51555  0.742115  1.192383   \n",
       "2  0.769231  0.241456  0.246914  0.184960  3.51555  0.742115  1.192383   \n",
       "3  0.769231  0.241456  0.259259  0.201767  3.51555  0.742115  1.192383   \n",
       "4  0.769231  0.241456  0.271605  0.186580  3.51555  0.742115  1.192383   \n",
       "\n",
       "   mean_vals  \n",
       "0   0.326172  \n",
       "1   0.326172  \n",
       "2   0.326172  \n",
       "3   0.326172  \n",
       "4   0.326172  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_df=patient_df.merge(temp_df[['Patient','volume','kurts','skews','mean_vals']],how='left',on='Patient')\n",
    "print(len(patient_df))\n",
    "patient_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:02.085533Z",
     "iopub.status.busy": "2020-10-01T09:33:02.084891Z",
     "iopub.status.idle": "2020-10-01T09:33:02.113744Z",
     "shell.execute_reply": "2020-10-01T09:33:02.113155Z"
    },
    "papermill": {
     "duration": 0.080094,
     "end_time": "2020-10-01T09:33:02.113866",
     "exception": false,
     "start_time": "2020-10-01T09:33:02.033772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "      <th>WHERE</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>Never smoked</th>\n",
       "      <th>Currently smokes</th>\n",
       "      <th>age</th>\n",
       "      <th>BASE</th>\n",
       "      <th>week</th>\n",
       "      <th>percent</th>\n",
       "      <th>volume</th>\n",
       "      <th>kurts</th>\n",
       "      <th>skews</th>\n",
       "      <th>mean_vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.236393</td>\n",
       "      <td>3.515550</td>\n",
       "      <td>0.742115</td>\n",
       "      <td>1.192383</td>\n",
       "      <td>0.326172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>ID00009637202177434476278</td>\n",
       "      <td>8</td>\n",
       "      <td>3660</td>\n",
       "      <td>85.282878</td>\n",
       "      <td>69</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.491270</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.453901</td>\n",
       "      <td>4.552959</td>\n",
       "      <td>2.920642</td>\n",
       "      <td>1.780273</td>\n",
       "      <td>0.300293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>ID00010637202177584971671</td>\n",
       "      <td>0</td>\n",
       "      <td>3523</td>\n",
       "      <td>94.724672</td>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.465825</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.529881</td>\n",
       "      <td>2.481575</td>\n",
       "      <td>0.693160</td>\n",
       "      <td>1.090820</td>\n",
       "      <td>0.337402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                    Patient  Weeks   FVC    Percent  Age   Sex  \\\n",
       "0       0  ID00007637202177411956430     -4  2315  58.253649   79  Male   \n",
       "9       9  ID00009637202177434476278      8  3660  85.282878   69  Male   \n",
       "18     18  ID00010637202177584971671      0  3523  94.724672   60  Male   \n",
       "\n",
       "   SmokingStatus  WHERE  Confidence  ... Never smoked  Currently smokes  \\\n",
       "0      Ex-smoker  train         NaN  ...            0                 0   \n",
       "9      Ex-smoker  train         NaN  ...            0                 0   \n",
       "18     Ex-smoker  train         NaN  ...            0                 0   \n",
       "\n",
       "         age      BASE      week   percent    volume     kurts     skews  \\\n",
       "0   0.769231  0.241456  0.179012  0.236393  3.515550  0.742115  1.192383   \n",
       "9   0.512821  0.491270  0.179012  0.453901  4.552959  2.920642  1.780273   \n",
       "18  0.282051  0.465825  0.179012  0.529881  2.481575  0.693160  1.090820   \n",
       "\n",
       "    mean_vals  \n",
       "0    0.326172  \n",
       "9    0.300293  \n",
       "18   0.337402  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#patient_df['skews'].isnull().values.any()\n",
    "df1 = patient_df[patient_df.isna().any(axis=1)]\n",
    "df1.head(20).drop_duplicates('Patient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:02.213189Z",
     "iopub.status.busy": "2020-10-01T09:33:02.212215Z",
     "iopub.status.idle": "2020-10-01T09:33:02.216446Z",
     "shell.execute_reply": "2020-10-01T09:33:02.215792Z"
    },
    "papermill": {
     "duration": 0.057981,
     "end_time": "2020-10-01T09:33:02.216597",
     "exception": false,
     "start_time": "2020-10-01T09:33:02.158616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male', 'Female', 'Ex-smoker', 'Never smoked', 'Currently smokes', 'age', 'percent', 'week', 'BASE', 'kurts', 'skews', 'mean_vals']\n"
     ]
    }
   ],
   "source": [
    "patient_df['kurts'].fillna((patient_df['kurts'].mean()), inplace=True)\n",
    "patient_df['skews'].fillna((patient_df['skews'].mean()), inplace=True)\n",
    "patient_df['mean_vals'].fillna((patient_df['mean_vals'].mean()), inplace=True)\n",
    "#patient_df['median_vals'].fillna((patient_df['median_vals'].mean()), inplace=True)\n",
    "#patient_df['std_vals'].fillna((patient_df['std_vals'].mean()), inplace=True)\n",
    "\n",
    "FE += ['kurts','skews','mean_vals']\n",
    "print(FE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:02.329381Z",
     "iopub.status.busy": "2020-10-01T09:33:02.328684Z",
     "iopub.status.idle": "2020-10-01T09:33:02.331926Z",
     "shell.execute_reply": "2020-10-01T09:33:02.331352Z"
    },
    "papermill": {
     "duration": 0.070415,
     "end_time": "2020-10-01T09:33:02.332051",
     "exception": false,
     "start_time": "2020-10-01T09:33:02.261636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, latent_features=10):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv3d(1, 16, 3)\n",
    "        self.conv2 = nn.Conv3d(16, 32, 3)\n",
    "        self.conv3 = nn.Conv3d(32, 96, 2)\n",
    "        self.conv4 = nn.Conv3d(96, 1, 1)\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2, return_indices=True)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=3, stride=3, return_indices=True)\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=2, stride=2, return_indices=True)\n",
    "        self.pool4 = nn.MaxPool3d(kernel_size=2, stride=2, return_indices=True)\n",
    "        self.fc1 = nn.Linear(10 * 10, latent_features)\n",
    "        # Decoder\n",
    "        self.fc2 = nn.Linear(latent_features, 10 * 10)\n",
    "        self.deconv0 = nn.ConvTranspose3d(1, 96, 1)\n",
    "        self.deconv1 = nn.ConvTranspose3d(96, 32, 2)\n",
    "        self.deconv2 = nn.ConvTranspose3d(32, 16, 3)\n",
    "        self.deconv3 = nn.ConvTranspose3d(16, 1, 3)\n",
    "        self.unpool0 = nn.MaxUnpool3d(kernel_size=2, stride=2)\n",
    "        self.unpool1 = nn.MaxUnpool3d(kernel_size=2, stride=2)\n",
    "        self.unpool2 = nn.MaxUnpool3d(kernel_size=3, stride=3)\n",
    "        self.unpool3 = nn.MaxUnpool3d(kernel_size=2, stride=2)\n",
    "\n",
    "    def encode(self, x, return_partials=True):\n",
    "        # Encoder\n",
    "        x = self.conv1(x)\n",
    "        up3out_shape = x.shape\n",
    "        x, i1 = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        up2out_shape = x.shape\n",
    "        x, i2 = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        up1out_shape = x.shape\n",
    "        x, i3 = self.pool3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        up0out_shape = x.shape\n",
    "        x, i4 = self.pool4(x)\n",
    "\n",
    "        x = x.view(-1, 10 * 10)\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        if return_partials:\n",
    "            return x, up3out_shape, i1, up2out_shape, i2, up1out_shape, i3, \\\n",
    "                   up0out_shape, i4\n",
    "\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, up3out_shape, i1, up2out_shape, i2, \\\n",
    "        up1out_shape, i3, up0out_shape, i4 = self.encode(x)\n",
    "\n",
    "        # Decoder\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = x.view(-1, 1, 1, 10, 10)\n",
    "        x = self.unpool0(x, output_size=up0out_shape, indices=i4)\n",
    "        x = self.deconv0(x)\n",
    "        x = self.unpool1(x, output_size=up1out_shape, indices=i3)\n",
    "        x = self.deconv1(x)\n",
    "        x = self.unpool2(x, output_size=up2out_shape, indices=i2)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.unpool3(x, output_size=up3out_shape, indices=i1)\n",
    "        x = self.deconv3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:02.827592Z",
     "iopub.status.busy": "2020-10-01T09:33:02.826897Z",
     "iopub.status.idle": "2020-10-01T09:33:02.835029Z",
     "shell.execute_reply": "2020-10-01T09:33:02.834484Z"
    },
    "papermill": {
     "duration": 0.06281,
     "end_time": "2020-10-01T09:33:02.835156",
     "exception": false,
     "start_time": "2020-10-01T09:33:02.772346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=5)\n",
    "groups = patient_df['Patient']\n",
    "patient_df['fold'] = -1\n",
    "for i, (train_idx, valid_idx) in enumerate(gkf.split(patient_df, patient_df['FVC'], groups)):\n",
    "    patient_df.loc[valid_idx, 'fold'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:02.985651Z",
     "iopub.status.busy": "2020-10-01T09:33:02.984884Z",
     "iopub.status.idle": "2020-10-01T09:33:02.987442Z",
     "shell.execute_reply": "2020-10-01T09:33:02.988088Z"
    },
    "papermill": {
     "duration": 0.107823,
     "end_time": "2020-10-01T09:33:02.988234",
     "exception": false,
     "start_time": "2020-10-01T09:33:02.880411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From https://github.com/Bjarten/early-stopping-pytorch\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        #score = -val_loss\n",
    "        score = val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            #self.save_checkpoint(val_loss, model)\n",
    "        elif score > self.best_score:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            #self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:03.084978Z",
     "iopub.status.busy": "2020-10-01T09:33:03.084288Z",
     "iopub.status.idle": "2020-10-01T09:33:03.149071Z",
     "shell.execute_reply": "2020-10-01T09:33:03.148417Z"
    },
    "papermill": {
     "duration": 0.115853,
     "end_time": "2020-10-01T09:33:03.149205",
     "exception": false,
     "start_time": "2020-10-01T09:33:03.033352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "autoencoder_models = []\n",
    "for path in MODELS:\n",
    "    state_dict = torch.load(path,map_location=torch.device('cpu'))\n",
    "    model = AutoEncoder()\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.float()\n",
    "    model.eval()\n",
    "    autoencoder_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:03.257989Z",
     "iopub.status.busy": "2020-10-01T09:33:03.256727Z",
     "iopub.status.idle": "2020-10-01T09:33:03.259931Z",
     "shell.execute_reply": "2020-10-01T09:33:03.259387Z"
    },
    "papermill": {
     "duration": 0.064541,
     "end_time": "2020-10-01T09:33:03.260046",
     "exception": false,
     "start_time": "2020-10-01T09:33:03.195505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function that generates all latent features\n",
    "class GenerateLatentFeatures:\n",
    "    def __init__(self, autoencoder_models, latent_dir):\n",
    "        #self.df = df.drop_duplicates(subset=['Patient'])\n",
    "        self.latent_dir = Path(latent_dir)\n",
    "        #self.cache_dir = Path(cache_dir)\n",
    "        \n",
    "    def __call__(self, img_id, img_array):\n",
    "        patient_id = img_id\n",
    "        cached_latent_file = self.latent_dir/f'{img_id}_lat.pt'\n",
    "\n",
    "        if cached_latent_file.is_file():\n",
    "            latent_features = torch.load(cached_latent_file, map_location=torch.device('cpu'))\n",
    "        else:\n",
    "            latent_features = []\n",
    "\n",
    "            if len(img_array)>HM_SLICES:\n",
    "                img_array = np.asarray(reduce_slices(img_array))\n",
    "                if len(img_array) < HM_SLICES:\n",
    "                   img_array = np.pad(img_array,[[0,HM_SLICES-len(img_array)],[0,0],[0,0]],constant_values=0.0)\n",
    "            else:\n",
    "                if len(img_array) < HM_SLICES:\n",
    "                   img_array = np.pad(img_array,[[0,HM_SLICES-len(img_array)],[0,0],[0,0]],constant_values=0.0)\n",
    "\n",
    "            img = torch.tensor(img_array).unsqueeze(0).float()\n",
    "            img = F.interpolate(img, size=256)\n",
    "            img = img.view(img.shape[0], 1, img.shape[1], img.shape[2], img.shape[3])\n",
    "            img = torch.tensor(img).to(device)\n",
    "\n",
    "            preds = 0.0\n",
    "            with torch.no_grad():\n",
    "                for model in autoencoder_models:\n",
    "                    pred = model.encode(img, return_partials=False).squeeze(0)\n",
    "                    preds+=pred.detach().cpu().numpy()\n",
    "                preds = preds/len(autoencoder_models)\n",
    "            latent_features.append(preds)\n",
    "\n",
    "            latent_features = np.concatenate(latent_features)\n",
    "            torch.save(latent_features, cached_latent_file)\n",
    "            \n",
    "        return latent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:03.361603Z",
     "iopub.status.busy": "2020-10-01T09:33:03.360751Z",
     "iopub.status.idle": "2020-10-01T09:33:03.363732Z",
     "shell.execute_reply": "2020-10-01T09:33:03.363202Z"
    },
    "papermill": {
     "duration": 0.058906,
     "end_time": "2020-10-01T09:33:03.363857",
     "exception": false,
     "start_time": "2020-10-01T09:33:03.304951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class fibrosisDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 rand=False,\n",
    "                 mode='train',\n",
    "                 extract_features=None,\n",
    "                ):\n",
    "        self.df = df.sort_values(by=['Patient','Weeks'],ascending=True).reset_index(drop=True)\n",
    "        self.rand = rand\n",
    "        self.mode = mode\n",
    "        self.extract_features = extract_features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        patient_id = row.Patient\n",
    "        label = row.FVC\n",
    "\n",
    "        tabular_data = row[FE]\n",
    "        \n",
    "        file_path = f'../input/dicom-arrays-processed/kaggle/dicom_arrays/{patient_id}.npy'\n",
    "        img_array = np.load(file_path)\n",
    "        \n",
    "        if self.extract_features:\n",
    "            features = self.extract_features(patient_id, img_array)\n",
    "        \n",
    "        if self.mode=='train' or self.mode=='valid':\n",
    "            return torch.tensor(tabular_data), torch.tensor(label), torch.tensor(features)\n",
    "        else:\n",
    "            return torch.tensor(tabular_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:03.481445Z",
     "iopub.status.busy": "2020-10-01T09:33:03.480570Z",
     "iopub.status.idle": "2020-10-01T09:33:03.485359Z",
     "shell.execute_reply": "2020-10-01T09:33:03.484760Z"
    },
    "papermill": {
     "duration": 0.076082,
     "end_time": "2020-10-01T09:33:03.485471",
     "exception": false,
     "start_time": "2020-10-01T09:33:03.409389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "      <th>WHERE</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>Currently smokes</th>\n",
       "      <th>age</th>\n",
       "      <th>BASE</th>\n",
       "      <th>week</th>\n",
       "      <th>percent</th>\n",
       "      <th>volume</th>\n",
       "      <th>kurts</th>\n",
       "      <th>skews</th>\n",
       "      <th>mean_vals</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.236393</td>\n",
       "      <td>3.51555</td>\n",
       "      <td>0.742115</td>\n",
       "      <td>1.192383</td>\n",
       "      <td>0.326172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>5</td>\n",
       "      <td>2214</td>\n",
       "      <td>55.712129</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.234568</td>\n",
       "      <td>0.215941</td>\n",
       "      <td>3.51555</td>\n",
       "      <td>0.742115</td>\n",
       "      <td>1.192383</td>\n",
       "      <td>0.326172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>7</td>\n",
       "      <td>2061</td>\n",
       "      <td>51.862104</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.184960</td>\n",
       "      <td>3.51555</td>\n",
       "      <td>0.742115</td>\n",
       "      <td>1.192383</td>\n",
       "      <td>0.326172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>9</td>\n",
       "      <td>2144</td>\n",
       "      <td>53.950679</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.201767</td>\n",
       "      <td>3.51555</td>\n",
       "      <td>0.742115</td>\n",
       "      <td>1.192383</td>\n",
       "      <td>0.326172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>11</td>\n",
       "      <td>2069</td>\n",
       "      <td>52.063412</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.241456</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.186580</td>\n",
       "      <td>3.51555</td>\n",
       "      <td>0.742115</td>\n",
       "      <td>1.192383</td>\n",
       "      <td>0.326172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                    Patient  Weeks   FVC    Percent  Age   Sex  \\\n",
       "0      0  ID00007637202177411956430     -4  2315  58.253649   79  Male   \n",
       "1      1  ID00007637202177411956430      5  2214  55.712129   79  Male   \n",
       "2      2  ID00007637202177411956430      7  2061  51.862104   79  Male   \n",
       "3      3  ID00007637202177411956430      9  2144  53.950679   79  Male   \n",
       "4      4  ID00007637202177411956430     11  2069  52.063412   79  Male   \n",
       "\n",
       "  SmokingStatus  WHERE  Confidence  ... Currently smokes       age      BASE  \\\n",
       "0     Ex-smoker  train         NaN  ...                0  0.769231  0.241456   \n",
       "1     Ex-smoker  train         NaN  ...                0  0.769231  0.241456   \n",
       "2     Ex-smoker  train         NaN  ...                0  0.769231  0.241456   \n",
       "3     Ex-smoker  train         NaN  ...                0  0.769231  0.241456   \n",
       "4     Ex-smoker  train         NaN  ...                0  0.769231  0.241456   \n",
       "\n",
       "       week   percent   volume     kurts     skews  mean_vals  fold  \n",
       "0  0.179012  0.236393  3.51555  0.742115  1.192383   0.326172     0  \n",
       "1  0.234568  0.215941  3.51555  0.742115  1.192383   0.326172     0  \n",
       "2  0.246914  0.184960  3.51555  0.742115  1.192383   0.326172     0  \n",
       "3  0.259259  0.201767  3.51555  0.742115  1.192383   0.326172     0  \n",
       "4  0.271605  0.186580  3.51555  0.742115  1.192383   0.326172     0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:03.587744Z",
     "iopub.status.busy": "2020-10-01T09:33:03.586994Z",
     "iopub.status.idle": "2020-10-01T09:33:06.950645Z",
     "shell.execute_reply": "2020-10-01T09:33:06.949800Z"
    },
    "papermill": {
     "duration": 3.417546,
     "end_time": "2020-10-01T09:33:06.950785",
     "exception": false,
     "start_time": "2020-10-01T09:33:03.533239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 12])\n",
      "tensor([2315, 2214, 2061, 2144, 2069, 2101, 2000, 2064])\n",
      "torch.Size([8, 10])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = fibrosisDataset(patient_df, mode='train', extract_features=GenerateLatentFeatures(autoencoder_models, latent_dir))\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "for (tabular_data,label, features) in train_loader:\n",
    "    inputs = tabular_data\n",
    "    print(tabular_data.shape)\n",
    "    print(label)\n",
    "    print(features.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:07.678581Z",
     "iopub.status.busy": "2020-10-01T09:33:07.675262Z",
     "iopub.status.idle": "2020-10-01T09:33:07.681489Z",
     "shell.execute_reply": "2020-10-01T09:33:07.682010Z"
    },
    "papermill": {
     "duration": 0.060986,
     "end_time": "2020-10-01T09:33:07.682175",
     "exception": false,
     "start_time": "2020-10-01T09:33:07.621189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNNFeatures(nn.Module):    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, in_ctscan_features=10):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.in_ctscan_features = in_ctscan_features\n",
    "        self.match_sz = nn.Linear(in_ctscan_features, input_dim)\n",
    "        \n",
    "        self.rnn = nn.RNN(input_dim*2, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu',dropout=0.1)\n",
    "        self.fc = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        #self.batch_size = None\n",
    "        #self.hidden = None\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = x1.view(-1, len(x1), len(x1[0]))\n",
    "        x2 = F.relu(self.match_sz(x2))\n",
    "        x2 = x2.view(-1, len(x2), len(x2[0]))\n",
    "        \n",
    "        x = torch.cat([x1, x2], dim=2)\n",
    "        \n",
    "        h0 = self.init_hidden(x)\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = F.relu(self.fc(out[:, -1, :]))\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        return h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:07.884250Z",
     "iopub.status.busy": "2020-10-01T09:33:07.880912Z",
     "iopub.status.idle": "2020-10-01T09:33:07.887698Z",
     "shell.execute_reply": "2020-10-01T09:33:07.887136Z"
    },
    "papermill": {
     "duration": 0.060976,
     "end_time": "2020-10-01T09:33:07.887818",
     "exception": false,
     "start_time": "2020-10-01T09:33:07.826842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metric(preds, targets):\n",
    "    sigma = preds[:, 2] - preds[:, 0]\n",
    "    sigma[sigma < 70] = 70\n",
    "    delta = (preds[:, 1] - targets).abs()\n",
    "    delta[delta > 1000] = 1000\n",
    "    return (-np.sqrt(2) * delta / sigma - torch.log(np.sqrt(2) * sigma)).mean()\n",
    "\n",
    "def fvc_loss(pred_fvc,true_fvc):\n",
    "    true_fvc=torch.reshape(true_fvc,pred_fvc[:,1].shape)\n",
    "    fvc_err=torch.abs(pred_fvc-true_fvc)\n",
    "    return fvc_err\n",
    "\n",
    "def quantile_loss(preds, target, quantiles):\n",
    "    assert not target.requires_grad\n",
    "    assert preds.size(0) == target.size(0)\n",
    "    losses = []\n",
    "    for i, q in enumerate(quantiles):\n",
    "        errors = target - preds[:, i]\n",
    "        losses.append(torch.max((q - 1)*errors, q*errors).unsqueeze(1))\n",
    "    loss = torch.mean(torch.sum(torch.cat(losses, dim=1), dim=1))\n",
    "    return loss\n",
    "\n",
    "def mloss(y_pred, y_true, _lambda):\n",
    "    return _lambda * quantile_loss(y_pred, y_true, quantiles) + (1 - _lambda)*metric(y_pred, y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:07.994226Z",
     "iopub.status.busy": "2020-10-01T09:33:07.989219Z",
     "iopub.status.idle": "2020-10-01T09:33:07.997853Z",
     "shell.execute_reply": "2020-10-01T09:33:07.997257Z"
    },
    "papermill": {
     "duration": 0.064009,
     "end_time": "2020-10-01T09:33:07.997976",
     "exception": false,
     "start_time": "2020-10-01T09:33:07.933967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    PREDS = []\n",
    "    TARGETS = []\n",
    "    optimizer.zero_grad()\n",
    "    running_score = 0.0\n",
    "    \n",
    "    bar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for steps, (tabular_data, label, features) in bar:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        tabular_data =  tabular_data.to(device).float()\n",
    "        label = label.to(device).float()\n",
    "        \n",
    "        preds = model(tabular_data, features)\n",
    "        loss = quantile_loss(preds, label, quantiles)\n",
    "        #loss = loss/accumulation_steps\n",
    "        \n",
    "        if fp16:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            \n",
    "#         if steps % accumulation_steps == 0:\n",
    "#             optimizer.step()\n",
    "#             scheduler.step()\n",
    "#             optimizer.zero_grad()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_score += metric(preds, label)\n",
    "        \n",
    "        PREDS.append(preds.detach())\n",
    "        TARGETS.append(label)\n",
    "        loss_np = loss.detach().cpu().numpy()\n",
    "        train_loss.append(loss_np)\n",
    "        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n",
    "        neptune.send_metric('lr_iter', optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    PREDS = torch.cat(PREDS).cpu().numpy()\n",
    "    TARGETS = torch.cat(TARGETS).cpu().numpy()   \n",
    "    score = running_score/len(train_loader)\n",
    "    train_loss = np.mean(train_loss)\n",
    "    \n",
    "    neptune.send_metric('train_loss', train_loss)\n",
    "    neptune.send_metric('train_score', score)\n",
    "    neptune.send_metric('lr', optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    return train_loss, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:08.103983Z",
     "iopub.status.busy": "2020-10-01T09:33:08.103250Z",
     "iopub.status.idle": "2020-10-01T09:33:08.106370Z",
     "shell.execute_reply": "2020-10-01T09:33:08.105850Z"
    },
    "papermill": {
     "duration": 0.061317,
     "end_time": "2020-10-01T09:33:08.106482",
     "exception": false,
     "start_time": "2020-10-01T09:33:08.045165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid(epoch):\n",
    "    model.eval()\n",
    "    valid_loss = []\n",
    "    PREDS = []\n",
    "    TARGETS = []\n",
    "    running_score = 0.0\n",
    "    \n",
    "    bar = tqdm(enumerate(valid_loader), total=len(valid_loader))\n",
    "    with torch.no_grad():\n",
    "        for steps, (tabular_data, label, features) in bar:\n",
    "\n",
    "            tabular_data =  tabular_data.to(device).float()\n",
    "            label = label.to(device).float()\n",
    "\n",
    "            preds = model(tabular_data, features)\n",
    "            loss = quantile_loss(preds, label, quantiles)\n",
    "            \n",
    "            running_score += metric(preds, label)\n",
    "\n",
    "            PREDS.append(preds.detach())\n",
    "            TARGETS.append(label)\n",
    "            loss_np = loss.detach().cpu().numpy()\n",
    "            valid_loss.append(loss_np)\n",
    "    \n",
    "    PREDS = torch.cat(PREDS).cpu().numpy()\n",
    "    TARGETS = torch.cat(TARGETS).cpu().numpy()   \n",
    "    score = running_score/len(valid_loader)\n",
    "    valid_loss = np.mean(valid_loss)\n",
    "    sigma_opt = mean_absolute_error(TARGETS, PREDS[:, 1])\n",
    "    unc = PREDS[:,2] - PREDS[:, 0]\n",
    "    sigma_mean = np.mean(unc)\n",
    "        \n",
    "    neptune.send_metric('valid_loss', valid_loss)\n",
    "    neptune.send_metric('valid_score', score)\n",
    "    neptune.send_metric('sigma_opt', sigma_opt)\n",
    "    neptune.send_metric('sigma_mean', sigma_mean)\n",
    "    \n",
    "    return valid_loss, score, PREDS, TARGETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T09:33:08.210580Z",
     "iopub.status.busy": "2020-10-01T09:33:08.207444Z",
     "iopub.status.idle": "2020-10-01T09:33:08.213696Z",
     "shell.execute_reply": "2020-10-01T09:33:08.214156Z"
    },
    "papermill": {
     "duration": 0.061455,
     "end_time": "2020-10-01T09:33:08.214315",
     "exception": false,
     "start_time": "2020-10-01T09:33:08.152860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_main(epochs, fold):\n",
    "    best_score = -np.inf\n",
    "    best_loss = np.inf\n",
    "    best_preds = None\n",
    "    for epoch in range(1, epochs+1):\n",
    "        start_time = time.time()\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        scheduler.step(epoch-1)\n",
    "        avg_train_loss, train_score = train(epoch) \n",
    "        avg_val_loss, valid_score, oof_pred, oof_target = valid(epoch)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        LOGGER.debug(f'  Epoch {epoch} - avg_train_loss: {avg_train_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.debug(f'  Epoch {epoch} - train_metric: {train_score}  valid_metric: {valid_score}')\n",
    "        if valid_score>best_score:\n",
    "            torch.save(model.state_dict(), f'model_fold_{fold}.pt')\n",
    "            best_score=valid_score\n",
    "            oof_csv = pd.DataFrame(data=oof_pred, columns=list(quantiles))\n",
    "            oof_csv['oof_target'] = oof_target\n",
    "            oof_csv.to_csv(f'oof_fold_{fold}.csv', index=False)\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'lr': optimizer.param_groups[0]['lr'],\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            }\n",
    "        torch.save(checkpoint, 'checkpoint.pt')\n",
    "        \n",
    "        early_stopping(avg_val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "    return valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 10135.883502,
     "end_time": "2020-10-01T12:22:04.144346",
     "exception": false,
     "start_time": "2020-10-01T09:33:08.260844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_score = []\n",
    "valid_labels = []\n",
    "for fold in range(CFG.n_fold):\n",
    "    print(f'Training fold {fold}')\n",
    "    \n",
    "    model = RNNFeatures(12, 150, 2, 3).to(device) \n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, CFG.epochs)\n",
    "\n",
    "    train_idx = np.where((patient_df['fold'] != fold))[0]\n",
    "    valid_idx = np.where((patient_df['fold'] == fold))[0]\n",
    "\n",
    "    train_data  = patient_df.loc[train_idx]\n",
    "    valid_data = patient_df.loc[valid_idx] \n",
    "\n",
    "    train_dataset = fibrosisDataset(train_data, mode='train',extract_features=GenerateLatentFeatures(autoencoder_models, latent_dir))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    valid_dataset = fibrosisDataset(valid_data, mode='train',extract_features=GenerateLatentFeatures(autoencoder_models, latent_dir))\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=20, verbose=False)\n",
    "    \n",
    "    score = run_main(CFG.epochs, fold)\n",
    "    valid_score.append(score)\n",
    "    del train_dataset, train_loader, valid_dataset, valid_loader, model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T12:22:48.796753Z",
     "iopub.status.busy": "2020-10-01T12:22:48.795898Z",
     "iopub.status.idle": "2020-10-01T12:22:49.143784Z",
     "shell.execute_reply": "2020-10-01T12:22:49.143001Z"
    },
    "papermill": {
     "duration": 22.797669,
     "end_time": "2020-10-01T12:22:49.143916",
     "exception": false,
     "start_time": "2020-10-01T12:22:26.346247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1542)\n",
      "176\n"
     ]
    }
   ],
   "source": [
    "oof = []\n",
    "for fold in range(CFG.n_fold):\n",
    "    oof_csv = pd.read_csv(f'./oof_fold_{fold}.csv')\n",
    "    oof.append(oof_csv)\n",
    "    \n",
    "oof = np.concatenate(oof)\n",
    "oof = np.transpose(oof)\n",
    "\n",
    "d =  {'0.2': oof[0], '0.5': oof[1], '0.8': oof[2], 'oof_target': oof[3], 'Patient':train_csv.Patient, 'Weeks':train_csv.Weeks}\n",
    "oof_preds = pd.DataFrame(data=d)\n",
    "oof_preds.to_csv('oof.csv', index=False)\n",
    "print(oof.shape)\n",
    "\n",
    "unique_ids = oof_preds.Patient.drop_duplicates()\n",
    "print(len(unique_ids))\n",
    "\n",
    "oof_columns = oof_preds.keys()\n",
    "oof_columns = list(oof_columns)\n",
    "\n",
    "oof_last = pd.DataFrame(columns=oof_columns)\n",
    "filtered = []\n",
    "for patient_id in unique_ids:\n",
    "    check = oof_preds.loc[oof_preds.Patient==str(patient_id)]\n",
    "    largest = check.nlargest(columns='Weeks',n=3, keep='first')\n",
    "    filtered.append(largest)\n",
    "\n",
    "filtered = np.concatenate(filtered)\n",
    "oof_last = pd.DataFrame(filtered, columns=oof_columns)\n",
    "oof_last.to_csv('oof_last.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T12:23:33.379273Z",
     "iopub.status.busy": "2020-10-01T12:23:33.378306Z",
     "iopub.status.idle": "2020-10-01T12:23:33.477660Z",
     "shell.execute_reply": "2020-10-01T12:23:33.476963Z"
    },
    "papermill": {
     "duration": 22.129755,
     "end_time": "2020-10-01T12:23:33.477795",
     "exception": false,
     "start_time": "2020-10-01T12:23:11.348040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oof score:  tensor(-6.7114, dtype=torch.float64)\n",
      "last 3 measurements score tensor(-6.7109, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "oof_csv = pd.read_csv('oof.csv')\n",
    "oof_predictions = torch.tensor(np.asarray(oof_csv[['0.2','0.5','0.8']]))\n",
    "oof_targets = torch.tensor(oof_csv['oof_target'])\n",
    "\n",
    "oof_last = pd.read_csv('oof_last.csv')\n",
    "oof_last_predictions = torch.tensor(np.asarray(oof_last[['0.2','0.5','0.8']]))\n",
    "oof_last_targets = torch.tensor(oof_last['oof_target'])\n",
    "\n",
    "oof_score = metric(oof_predictions, oof_targets)\n",
    "oof_last_score = metric(oof_last_predictions, oof_last_targets)\n",
    "print(\"oof score: \",oof_score)\n",
    "print(\"last 3 measurements score\", oof_last_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T12:24:18.021278Z",
     "iopub.status.busy": "2020-10-01T12:24:18.019875Z",
     "iopub.status.idle": "2020-10-01T12:24:18.052666Z",
     "shell.execute_reply": "2020-10-01T12:24:18.053136Z"
    },
    "papermill": {
     "duration": 22.056955,
     "end_time": "2020-10-01T12:24:18.053303",
     "exception": false,
     "start_time": "2020-10-01T12:23:55.996348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best oof score:  tensor(-6.6694, dtype=torch.float64)\n",
      "best last 3 measurements score tensor(-6.6752, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Check against best scored kernel oof predictions\n",
    "'''\n",
    "oof_check = pd.read_csv(f'../input/oof-check/oof.csv')\n",
    "oof_predictions1 = torch.tensor(np.asarray(oof_check[['0.2','0.5','0.8']]))\n",
    "oof_targets1 = torch.tensor(oof_check['oof_target'])\n",
    "\n",
    "oof_last3 = pd.read_csv(f'../input/oof-check/best_oof_last3.csv')\n",
    "oof_last3_predictions = torch.tensor(np.asarray(oof_last3[['0.2','0.5','0.8']]))\n",
    "oof_last3_targets = torch.tensor(oof_last3['oof_target'])\n",
    "\n",
    "oof_score = metric(oof_predictions1, oof_targets1)\n",
    "oof_last3_score = metric(oof_last3_predictions, oof_last3_targets)\n",
    "print(\"best oof score: \",oof_score)\n",
    "print(\"best last 3 measurements score\", oof_last3_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T12:25:02.733030Z",
     "iopub.status.busy": "2020-10-01T12:25:02.732347Z",
     "iopub.status.idle": "2020-10-01T12:25:05.857035Z",
     "shell.execute_reply": "2020-10-01T12:25:05.856379Z"
    },
    "papermill": {
     "duration": 25.585414,
     "end_time": "2020-10-01T12:25:05.857165",
     "exception": false,
     "start_time": "2020-10-01T12:24:40.271751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "neptune.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 10389.458836,
   "end_time": "2020-10-01T12:25:27.931100",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-01T09:32:18.472264",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
